# SS-DMFO 优化方法总结报告

## 一、项目目标

为93,000+用户生成符合真实城市统计特征的轨迹坐标，需要同时满足：
1. **空间约束**：H/W/O各类型的空间分布匹配真实数据
2. **交互约束**：HW/HO/WO共现模式匹配真实数据（稀疏矩阵，HW有103万非零项）

**评估指标**：Jensen-Shannon Divergence (JSD)，越低越好

---

## 二、方法演进历程

### 2.1 初始版本：SS-DMFO GPU with top_k

**实现**：
- GPU加速的对偶优化
- 使用`top_k`参数选择"重要"的交互位置

**结果**（100用户）：
| 指标 | 数值 |
|------|------|
| Spatial JSD | ~0.02 |
| Interaction JSD | ~0.60 |

**发现的问题**：
- `top_k=50`只覆盖2,500个交互位置
- 真实HW有1,034,099个非零项
- **结构性缺陷**：top_k假设"重要交互位置"可预先确定，但真实交互来自用户个体行为

**关键发现**：
```
top_k=50  → Interaction JSD ≈ 0.60
top_k=200 → Interaction JSD ≈ 0.12
```
说明k值是瓶颈，但增加k会导致OOM。

---

### 2.2 专家方案：SS-DMFO 3.0 Sparse

基于专家团队建议，实现了全新的稀疏优化器：

**核心改进**：

| 组件 | 旧方法 | 新方法 | 复杂度变化 |
|------|--------|--------|-----------|
| 支撑集 | top_k近似 | 真实约束S | 消除结构性缺陷 |
| 外循环 | O(N·G²) 外积 | SDDMM O(N·\|S\|) | **降低1600倍** |
| 内循环 | 稠密矩阵乘法 | SpMM 稀疏乘法 | 显著降低 |

**关键代码**：
- `optimizer_sparse.py`: SDDMM + SpMM实现
- `SupportSet`: 从真实约束提取支撑集
- `SparsePotentials`: 稀疏beta势函数

---

## 三、调参历程

### 3.1 参数配置演进

| 参数 | 初始值 | 最终值 | 调整原因 |
|------|--------|--------|----------|
| `max_iter` | 100 | 80-150 | 平衡收敛和时间 |
| `temp_init` | 2.0 | 2.0 | 保持 |
| `temp_final` | 0.5 | 0.3 | 更低温度→更sharp分布 |
| `gumbel_scale` | 0.3 | 0.2 | 降低噪声→更好收敛 |
| `gumbel_decay` | 0.995 | 0.98 | 更快衰减 |
| `gumbel_final` | 0.05 | 0.02 | 最终阶段低噪声 |
| `phase1_ratio` | 0.2 | 0.5 | 更长Phase1→更好空间收敛 |
| `lr_alpha` | 0.1 | 0.15 | 更快空间收敛 |
| `lr_beta` | 0.05 | 0.02 | 降低→不干扰空间 |
| `gpu_batch_size` | 1000 | 500 | 避免OOM |
| `sddmm_batch_size` | 500 | 100 | 避免SDDMM OOM |

### 3.2 遇到的Bug和修复

1. **GPU OOM**（1000用户时）
   - 原因：MFVI中的SpMM和SDDMM产生大量中间张量
   - 修复：分批处理用户（mini-batch）

2. **最终分配与优化不一致**
   - 原因：优化在T=2.0开始，best_iter在T=0.36，但最终分配用T=0.1
   - 修复：保存best_iter时的温度，最终分配使用相同温度

3. **Gumbel scale=0错误**
   - 原因：Gumbel分布的scale参数不能为0
   - 修复：当scale≤1e-6时跳过噪声添加

4. **评估指标不一致**
   - 原因：优化在支撑集S上（103万位置），评估用top_k=50（2500位置）
   - 部分修复：添加Support Set JSD评估

---

## 四、最终结果

### 4.1 优化过程中的指标

```
Iter   0 [P1]: Spatial=0.5336
Iter  40 [P2]: Spatial=0.0588
Iter  70 [P2]: Spatial=0.0212, Interact=0.2212
Best interaction: 0.1962 at iter 75
```

### 4.2 最终评估结果

| 方法 | Spatial JSD | Interaction JSD | Support JSD | 时间 |
|------|-------------|-----------------|-------------|------|
| IPF (baseline) | **0.0000** | 0.6352 | 0.6348 | 13s |
| Sparse-100 | 0.1186 | 0.42 | 0.20 | 95s |
| Sparse-1000 | 0.1186 | 0.35 | 0.20 | 756s |
| Sparse-5000 | 0.1186 | 0.34 | 0.20 | 3732s |

### 4.3 关键差距分析

**优化过程 vs 最终评估**：
| 阶段 | Spatial JSD |
|------|-------------|
| 优化中 (iter 70) | 0.0212 |
| 最终评估 | 0.1186 |

差距来源：
- H和W位置数量少（1-3个），统计不稳定
- O位置多（~10个），聚合稳定（JSD=0.0221接近优化值）

---

## 五、核心问题分析

### 5.1 优化方法的根本困难

1. **优化指标与评估指标不一致**
   - 优化时：在支撑集S上计算JSD
   - 评估时：在生成分布的top_k位置上计算
   - 两者是不同的度量

2. **空间和交互约束冲突**
   - alpha控制空间分布
   - beta控制交互约束
   - 更新beta会改变分配，从而影响空间分布

3. **温度/噪声敏感性**
   - 不同温度下，同一个alpha产生完全不同的分布
   - Gumbel噪声的随机性导致聚合不稳定

4. **位置数量不平衡**
   - H: 1-3个位置/用户
   - W: 1-5个位置/用户
   - O: 1-10个位置/用户
   - 少量位置的聚合统计不稳定

### 5.2 IPF为什么更好（在空间约束上）

IPF使用**乘性更新**（Sinkhorn算法）：
- 直接缩放分配矩阵以匹配边际分布
- 数学上保证收敛到精确边际匹配
- 不需要调参

我们的方法使用**加性更新**（梯度下降）：
- 通过梯度更新对偶变量alpha
- 然后用softmax生成分配
- 温度和噪声会影响结果

---

## 六、尝试过但效果有限的方法

1. **增加迭代次数** → 效果有限
2. **调整学习率比例** → 轻微改善
3. **更低的温度** → 收敛问题
4. **更少的噪声** → 多样性不足
5. **更长的Phase1** → 空间改善但交互恶化
6. **多样本平均** → 轻微改善

---

## 七、结论与建议

### 7.1 当前方法的局限

基于对偶优化的方法在同时满足空间和交互约束时存在根本困难：
- 两个目标在优化过程中相互干扰
- 需要大量调参且结果不稳定
- 最终评估与优化过程不一致

### 7.2 可能的前进方向

**方向1：混合方法**
```
Phase 1: IPF精确匹配空间分布 (Spatial JSD = 0)
Phase 2: 在保持空间约束的情况下优化交互
```

**方向2：深度学习方法**
- 输入：用户life pattern (24h × 位置概率)
- 输出：位置的物理坐标分布
- 损失：空间JSD + 交互JSD
- 优势：端到端学习，自动调参

**方向3：Sinkhorn/G-IPF风格的乘性更新**
- 使用乘性更新替代梯度下降
- 数学上更稳定
- 专家团队推荐的方向

---

## 八、代码结构

```
ssdmfo/core/
├── optimizer_sparse.py    # SS-DMFO 3.0 Sparse实现
│   ├── SparseConfig       # 配置参数
│   ├── SupportSet         # 支撑集提取
│   ├── SparsePotentials   # 稀疏势函数
│   ├── SparseAdamOptimizer # Adam优化器
│   ├── SSDMFOSparse       # 主优化器
│   │   ├── _sddmm_aggregate()  # SDDMM外循环
│   │   ├── _mfvi_spmm()        # SpMM内循环
│   │   └── _batch_forward()    # 前向传播
│   └── ...
└── optimizer_gpu.py       # 旧版GPU优化器（已弃用）

test_sparse.py             # 完整测试脚本
test_sparse_quick.py       # 快速测试脚本
```

---

## 九、关键数据

- 用户数：93,361
- 网格大小：221 × 185 = 40,885
- 支撑集大小：
  - HW: 1,034,099 (覆盖0.06%)
  - HO: 3,988,341 (覆盖0.24%)
  - WO: 3,975,927 (覆盖0.24%)

---

*报告生成日期：2025-11-26*
*作者：SS-DMFO Team*
